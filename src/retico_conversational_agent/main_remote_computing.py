import os

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
from functools import partial
import torch
import argparse
import json

import retico_core
from retico_core import network
from retico_core.log_utils import (
    filter_cases,
    configurate_plot,
    plot_once,
)
from retico_wozmic import WOZMicrophoneModule
from retico_pttmic import PTTMicrophoneModule

from retico_amq import define_amq_network

import retico_conversational_agent as agent
from retico_conversational_agent import (
    DMIU,
    SpeakerAlignementIU,
    TextAlignedAudioIU,
)


def main_DM_remote_computing_remote(dh: bool, quantized: bool, llm: str, local_llm: str):
    """The `main_DM_remote_computing_remote` and `main_DM_remote_computing_local` functions creates the dialog system
    in two parts, communicating with one another through ActiveMQ. The idea is to have all the dialog system's modules
    that are supposed to run on a remote computer and runs a dialog system that is able to have a conversation with the
    user.

    The dialog system is composed of different modules: - a Microphone :
    captures the user's voice - an ASR : transcribes the user's voice
    into text - a LLM : generates a textual answer to the trancription
    from user's spoken sentence. - a TTS : generates a spoken answer
    from the LLM's textual answer. - a Speaker : outputs the spoken
    answer generated by the system.

    We provide the system with a scenario (contained in the
    "system_prompt") that it will follow through the conversation : The
    system is a teacher and it will teach mathematics to a 8-year-old
    child student (the user)

    the parameters defined : - model_path : the path to the weights of
    the LLM that will be used in the dialog system. - system_prompt : a
    part of the prompt that will be given to the LLM at every agent turn
    to set the scenario of the conversation. - printing : an argument
    that set to True will print a lot of information useful for
    degugging. - rate : the target audio signal rate to which the audio
    captured by the microphone will be converted to (so that it is
    suitable for every module) - frame_length : the chosen frame length
    in seconds at which the audio signal will be chunked. - log_folder :
    the path to the folder where the logs (information about each
    module's latency) will be saved.

    It is recommended to not modify the rate and frame_length parameters
    because the modules were coded with theses values and it is not
    ensured that the system will run correctly with other values.
    """

    # parameters definition
    device = "cuda" if torch.cuda.is_available() else "cpu"
    printing = False
    log_folder = "logs/run"
    frame_length = 0.02
    tts_frame_length = 0.2
    rate = 16000
    tts_model = "jenny"
    model_path = "./models/mistral-7b-instruct-v0.2.Q4_K_S.gguf"
    system_prompt = "This is a spoken dialog scenario between a teacher and a 8 years old child student.\
        The teacher is teaching mathemathics to the child student.\
        As the student is a child, the teacher needs to stay gentle all the time. Please provide the next valid response for the followig conversation.\
        You play the role of a teacher. Here is the beginning of the conversation :"
    plot_config_path = "configs/plot_config_DM.json"
    plot_live = False
    prompt_format_config = "configs/prompt_format_config.json"
    context_size = 2000
    dh_size = 1800

    # AMQ parameters
    destination_local_mic_out = "/topic/local_mic_out"
    destination_local_spk_out = "/topic/local_spk_out"
    destination_remote_dm_out = "/topic/remote_dm_out"
    destination_remote_tts_out = "/topic/remote_tts_out"
    ip = "localhost"
    # print(f"IP = {ip}")
    port = "61613"

    # filters
    filters = [
        partial(
            filter_cases,
            cases=[
                [("debug", [True])],
                [("level", ["warning", "error"])],
            ],
        )
    ]
    # configurate logger
    # terminal_logger, _ = retico_core.log_utils.configurate_logger(log_folder, filters=filters)
    terminal_logger, _ = retico_core.log_utils.configurate_logger()

    # # configure plot
    # configurate_plot(
    #     is_plot_live=plot_live,
    #     refreshing_time=1,
    #     plot_config_path=plot_config_path,
    #     window_duration=30,
    # )

    if dh:
        dialogue_history = agent.DialogueHistory(
            prompt_format_config,
            terminal_logger=terminal_logger,
            initial_system_prompt=system_prompt,
            context_size=dh_size,
        )
        llm_init = agent.LlmDmModule
    else:
        dialogue_history = agent.DialogueHistoryHf(
            terminal_logger=terminal_logger,
            initial_system_prompt=system_prompt,
            context_size=dh_size,
        )
        llm_init = agent.LlmDmModuleHf

    # create modules
    vad = agent.VadModule(
        input_framerate=rate,
        frame_length=frame_length,
    )

    dm = agent.DialogueManagerModule(
        dialogue_history=dialogue_history,
        input_framerate=rate,
        frame_length=frame_length,
    )
    dm.add_repeat_policy()
    dm.add_soft_interruption_policy()
    dm.add_continue_policy()

    asr = agent.AsrDmModule(
        device=device,
        full_sentences=True,
        input_framerate=rate,
    )

    model_repo = None
    model_name = None
    if local_llm is None:
        with open("configs/LLMs.json") as models_file:
            models = json.load(models_file)
            model = models[llm]
            if quantized:
                model_repo = model["quantized"]["repo"]
                model_name = model["quantized"]["model"]
            else:  # TODO: implement original HF LLM initialization
                model_repo = model["original"]["repo"]

    llm = llm_init(
        model_path=local_llm,
        model_repo=model_repo,
        model_name=model_name,
        dialogue_history=dialogue_history,
        printing=printing,
        device=device,
        verbose=True,
    )

    tts = agent.TtsDmModule(
        language="en",
        model=tts_model,
        printing=printing,
        frame_duration=tts_frame_length,
        device=device,
    )

    # create network
    vad.subscribe(dm)
    dm.subscribe(asr)
    dm.subscribe(llm)
    dm.subscribe(tts)
    asr.subscribe(llm)
    llm.subscribe(tts)

    dict_out = [
        {"module": dm, "destination": destination_remote_dm_out},
        {"module": tts, "destination": destination_remote_tts_out},
    ]
    dict_in = [
        {"destination": destination_local_mic_out, "iu_type": retico_core.audio.AudioIU, "subscriber_modules": [vad]},
        {
            "destination": destination_local_spk_out,
            "iu_type": SpeakerAlignementIU,
            "subscriber_modules": [vad, llm, dm],
        },
    ]
    define_amq_network(
        modules_out_dict=dict_out, modules_in_dict=dict_in, verbose=printing, ip=ip, port=port, message_is_bytes=True
    )

    # bridge_dm = AMQBridge([], destination_remote_dm_out)
    # bridge_tts = AMQBridge([], destination_remote_tts_out)
    # aw = AMQWriterBytes(ip=ip, port=port, verbose=printing)
    # ar_mic_out = AMQReaderBytes(ip=ip, port=port, verbose=printing)
    # ar_mic_out.add(destination=destination_local_mic_out, target_iu_type=retico_core.audio.AudioIU)
    # ar_spk_out = AMQReaderBytes(ip=ip, port=port, verbose=printing)
    # ar_spk_out.add(destination=destination_local_spk_out, target_iu_type=SpeakerAlignementIU)

    # # create network
    # vad.subscribe(dm)
    # dm.subscribe(asr)
    # dm.subscribe(llm)
    # dm.subscribe(tts)
    # asr.subscribe(llm)
    # llm.subscribe(tts)
    # tts.subscribe(bridge_tts)
    # dm.subscribe(bridge_dm)
    # bridge_tts.subscribe(aw)
    # bridge_dm.subscribe(aw)
    # ar_mic_out.subscribe(vad)
    # ar_spk_out.subscribe(vad)
    # ar_spk_out.subscribe(llm)
    # ar_spk_out.subscribe(dm)

    # running system
    try:
        network.run(vad)
        terminal_logger.info("Dialog system running until ENTER key is pressed")
        input()
        network.stop(vad)
    except Exception:
        terminal_logger.exception("exception in main")
        network.stop(vad)
    # finally:
    #     plot_once(
    #         plot_config_path=plot_config_path,
    #     )


def main_DM_remote_computing_local(wozmic: bool, pttmic: bool):
    # parameters definition
    printing = False
    log_folder = "logs/run"
    tts_model_samplerate = 48000
    rate = 16000
    frame_length = 0.02
    plot_config_path = "configs/plot_config_DM.json"
    plot_live = True

    # AMQ parameters
    destination_local_mic_out = "/topic/local_mic_out"
    destination_local_spk_out = "/topic/local_spk_out"
    destination_remote_dm_out = "/topic/remote_dm_out"
    destination_remote_tts_out = "/topic/remote_tts_out"
    ip = "localhost"
    port = "61613"

    # filters
    filters = [
        partial(
            filter_cases,
            cases=[
                [("debug", [True])],
                [("level", ["warning", "error"])],
            ],
        )
    ]
    # configurate logger
    # terminal_logger, _ = retico_core.log_utils.configurate_logger(log_folder, filters=filters)
    terminal_logger, _ = retico_core.log_utils.configurate_logger()

    # # configure plot
    # configurate_plot(
    #     is_plot_live=plot_live,
    #     refreshing_time=1,
    #     plot_config_path=plot_config_path,
    #     window_duration=30,
    # )

    # create modules
    if wozmic:
        mic = WOZMicrophoneModule(frame_length=frame_length, rate=rate)
    elif pttmic:
        mic = PTTMicrophoneModule(frame_length=frame_length, rate=rate)
    else:
        mic = retico_core.audio.MicrophoneModule()

    speaker = agent.SpeakerDmModule(
        rate=tts_model_samplerate,
    )

    dict_out = [
        {"module": mic, "destination": destination_local_mic_out},
        {"module": speaker, "destination": destination_local_spk_out},
    ]
    dict_in = [
        {"destination": destination_remote_dm_out, "iu_type": DMIU, "subscriber_modules": [speaker]},
        {
            "destination": destination_remote_tts_out,
            "iu_type": TextAlignedAudioIU,
            "subscriber_modules": [speaker],
        },
    ]
    define_amq_network(
        modules_out_dict=dict_out, modules_in_dict=dict_in, verbose=printing, ip=ip, port=port, message_is_bytes=True
    )

    # bridge_mic = AMQBridge([], destination_local_mic_out)
    # bridge_spk = AMQBridge([], destination_local_spk_out)
    # aw = AMQWriterBytes(ip=ip, port=port, verbose=printing)
    # ar = AMQReaderBytes(ip=ip, port=port, verbose=printing)
    # ar.add(destination=destination_remote_dm_out, target_iu_type=DMIU)
    # ar.add(destination=destination_remote_tts_out, target_iu_type=TextAlignedAudioIU)

    # # create network
    # mic.subscribe(bridge_mic)
    # speaker.subscribe(bridge_spk)
    # bridge_mic.subscribe(aw)
    # bridge_spk.subscribe(aw)
    # ar.subscribe(speaker)

    # running system
    try:
        network.run(mic)
        terminal_logger.info("Dialog system running until ENTER key is pressed")
        input()
        network.stop(mic)
    except Exception:
        terminal_logger.exception("exception in main")
        network.stop(mic)
    # finally:
    #     plot_once(
    #         plot_config_path=plot_config_path,
    #     )


if __name__ == "__main__":

    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--remote_computing",
        "-c",
        help="Set to local or remote to run the system in multiple parts for remote computing (like clusters).",
        type=str,
        choices=["local", "remote"],
    )
    parser.add_argument(
        "--handmade_DH",
        "-hdh",
        help="Use Handmade Dialogue History (and corres. LLM Module) instead of classical Huggingface's apply_chat_template.",
        action=argparse.BooleanOptionalAction,
    )
    parser.add_argument(
        "--woz_mic",
        "-wozmic",
        help="Use Wizard-Of-Oz Microphone, that plays audio when 'm' key pressed, instead of classical Microphone.",
        action=argparse.BooleanOptionalAction,
    )
    parser.add_argument(
        "--ptt_mic",
        "-pttmic",
        help="Use Wizard-Of-Oz Microphone, that plays audio when 'm' key pressed, instead of classical Microphone.",
        action=argparse.BooleanOptionalAction,
    )
    parser.add_argument(
        "--llm",
        "-llm",
        help="Choose the LLM you want to use.",
        type=str,
        default="llama3.1_8B_I",
    )
    parser.add_argument(
        "--quantized_llm",
        "-qllm",
        help="Use Quantized version of LLM.",
        action=argparse.BooleanOptionalAction,
        default=True,
    )
    parser.add_argument(
        "--local_llm",
        "-local_llm",
        help="Set the path to the local LLM weights you want to use.",
        type=str,
        default=None,
    )
    args = parser.parse_args()
    if args.remote_computing is not None:
        if args.remote_computing == "local":
            main_DM_remote_computing_local(
                wozmic=args.woz_mic,
                pttmic=args.ptt_mic,
            )
        elif args.remote_computing == "remote":
            main_DM_remote_computing_remote(
                dh=args.handmade_DH,
                llm=args.llm,
                quantized=args.quantized_llm,
                local_llm=args.local_llm,
            )
        else:
            print("remote_computing argument set to something else than remote or local.")
    # plot_once(plot_config_path="configs/plot_config_DM.json")
